trControl = ctrl)
#como hemos utilizado preProcess en la configuracion de train, entonces no es
#necesario preprocesar nuestos datos de test:
#ya viene incluindo en knnk3
oknnk3 <- predict(knnk3, TrainData)
#ahora se repetira lo mismo para k=5, almacenando los resultados y modelos en
#las variables correspondientes.
# TO DO
knnk5 <- train(TrainData, TrainClasses,
method = "knn",
preProcess= c("center","scale"),
tuneLength = 1,
tuneGrid = data.frame(k=5),
trControl = ctrl
)
oknnk5 <- predict(knnk5, TrainData)
confusionMatrix(oknnk3, TrainClasses)
resultados<-confusionMatrix(oknnk3, TrainClasses)
apply((resultados$byClass,2,mean)
apply(resultados$byClass,2,mean)
res3<-multiClassSummary(datos3, lev=levels(TrainClasses))
head(datos3)
res5<-multiClassSummary(datos5, lev=levels(TrainClasses))
res3
resKnn3<-confusionMatrix(oknnk3, TrainClasses)
#Repita lo mismo para el clasificador knnk5
resKnn5<-confusionMatrix(oknnk5, TrainClasses)
datos5 <-data.frame(obs=TrainClasses, pred=oknnk5)
res5<-multiClassSummary(datos5, lev=levels(TrainClasses))
#entrenaremos un clasificador knn utilizando caret, sin validacion cruzada
#sin ajuste de parametros, para k=3.
#Usaremos los datos <trnD,trnC> para entrenar y <tstD,tstC> para validar
#
knnk3b <- train(trnD, trnC,
method = "knn",
preProcess= c("center","scale"),
tuneLength = 1,
tuneGrid = data.frame(k=3),
trControl = control
)
knnk3b
#como hemos utilizado preProcess en la configuracion de train, entonces no es
#necesario preprocesar nuestos datos de test: ya viene incluindo en knnk3
oknnk3b <- predict(knnk3b, tstD)
knnk3$finalModel
#Obtenga ahora los promedios de las medidas de prestaciones del clasificador knnk3b
#utilice la funcion multiClassSummary
confusionMatrix(oknnk3b, tstC)
datos5b<-data.frame(obs=tstC, pred=oknnk5b)
res5b<-multiClassSummary(datos5b, lev=levels(TrainClasses))
datos3b<-data.frame(obs=tstC, pred=oknnk3b)
res3b<-multiClassSummary(datos3b, lev=levels(TrainClasses))
res3b[1]
res5b[1]
#Por casualidad, se comprobara ahora las prestaciones de knnk3b y knnk5b con todo
#el dataset
oknnk3bT =
oknnk5bT =
#Compare estos resultados con los obtenidos anteriormente.
#Existe algo sorprendente?
#############################################################################
#Lo que ha ocurrido es debido a:
# 1.- cuando entrenamos con todos los datos, no hay forma de evaluar el modelo,
#     al no disponer de datos extra para evaluacion.
# 2.- cuando entrenamos con un conjunto de datos para reservar otro conjunto
#     para utilizarlo en la evaluacion, estamos posiblemente obteniendo modelos
#     desviados. Si tenemos la mejor suerte del mundo, elegiremos un subconjunto
#     de train representativo de todos los casos, asi como un subconjunto de test
#     variado. ESTO ES CONFIAR DEMASIADO EN LA SUERTE.
# 3.- Como se pudo apreciar, el resultado tras evaluar sobre todo el conjunto de
#     entrenamiento y test (TrainData), los resultados son peores. Esto es debido
#     a lo comentado anteriormente sobre los subconjuntos de test, pero tambien
#     es debido a que posiblemente no sean los mejores valores de k
#
#Que se puede hacer entonces?
# 1.- Introducir el ajuste de los parametros de los clasificadores
#Es decir, se fijaran combinaciones de valores de parametros que se consideren
#validos para entrenar el modelo. En el caso de knn, se podra dar valores impares
#del valor de k.
#
# 2.- Conjuntamente con validacion cruzada (y posiblemente, repeticiones).
#Con la validacion cruzada podremos entrenar/evaluar los modelos con diferentes
#pares de conjuntos de train/test. Luego, es posible obtener unos valores promedio
#de prestaciones de clasificador; este valor promedio sera mas independiente del
#remuestreo realizado.
#
#En definitiva, para cada configuracion de parametros se tendra el comportamiento
#medio, independiente del remuestreo, que permitira determinar cual o cuales son
#las mejores combiaciones de parametros.
#
#Todo esto se implementa usando la funcion trainControl y train con mas argumentos.
#especificar los valores posibles para los parametros
kvalues = data.frame(k = c(3,5,7, 9,11,13, 15,17,19, 21))
trnCtrl = trainControl(method = 'cv', number = 10, search = 'grid',
savePredictions = TRUE, classProbs = TRUE )
modelo = train(x=TrainData, y=TrainClasses,
method = "knn",
preProcess= c("center","scale"),
metric = 'accuracy',
tuneGrid = kvalues,
trControl = trnCtrl
)
#Observemos el modelo obtenido
print(modelo)
multiClassSummary(data.frame(obs=tstC, pred=outModelo), lev = levels(tstC), model = 'knn')
#Una vez obtenido el modelo, cada vez que se necesite clasificar se utilizara
#la funcion predict:
outModelo = predict(modelo, tstD)
multiClassSummary(data.frame(obs=tstC, pred=outModelo), lev = levels(tstC), model = 'knn')
# El perceptron
#Vamos a construir la red neuronal mÃ¡s sencilla que hay, el PerceptrÃ³n lineal. Vamos a utilizar como datos de entrenamiento un subconjunto de los datos iris
# leemos el conjunto de datos
data(iris)
# Seleccionamos las longitudes del pÃ©talo y del sÃ©palo , y la clase
irissubdf <- iris[c(1:5,51:56), c(1, 3, 5)]
irissubdf
names(irissubdf) <- c("sepal", "petal", "species")
head(irissubdf)
summary(irissubdf)
# Añadimos una variable binaria como variable a predecir,
#1 si es versicolor, -1 si es setosa
irissubdf[, 4] <- 1
head(irissubdf)
irissubdf[irissubdf[, 3] == "setosa", 4] <- -1
head(irissubdf)
x <- irissubdf[, c(1, 2)]
y <- irissubdf[, 4]
x
y
irissubdf[, 4] <- 1
irissubdf[irissubdf[, 3] == "setosa", 4] <- -1
x <- irissubdf[, c(1, 2)]
y <- irissubdf[, 4]
x
y
library(ggplot2)
Plotdatos<-ggplot(irissubdf, aes(x = sepal, y = petal)) +
geom_point(aes(colour=species, shape=species), size = 3) +
xlab("sepal length") +
ylab("petal length") +
ggtitle("Species vs longitud del sepalo y petalo")
Plotdatos
dibuja.hiperplano<-function(x,b,w,punto=NA)
{
plot(x, cex=0.2, xlim=c(-5,7), ylim=c(-2,5))
points(subset(x,y==1), col="black", pch="+", cex=2)
points(subset(x,y==-1), col="red", pch="*", cex=2)
indep<- -b/w[2]
pendiente<- -w[1]/w[2]
abline(indep,pendiente, col="green")
if (!is.na(punto)){points(punto, col="blue", pch="o", cex=2)}
}
perceptron <- function(x, y, eta, niter) {
# inicializacion vector de pesos
pesos <- rep(0, ncol(x))
b<-0
errors <- rep(0, niter)
# Bucle iteraciones
for (jj in 1:niter) {
# Bucle sobre el conjunto de entrenameinto
for (ii in 1:length(y)) {
# Prediccion de clase utilizando funcion salto
z <- sum(pesos* as.numeric(x[ii, ])) + b
if(z < 0) {
ypred <- -1
} else {
ypred <- 1
}
# Modificacion de pesos
delta.pesos <- eta * (y[ii] - ypred) * as.numeric(x[ii, ])
pesos <- pesos + delta.pesos
delta.b<- eta * (y[ii] - ypred)
b <- b + delta.b
if (niter==1) {dibuja.hiperplano(x,b,pesos,x[ii,])}
# Actualiza numero de errores
if ((y[ii] - ypred) != 0.0) {
errors[jj] <- errors[jj] + 1
}
}
if (niter>1) {dibuja.hiperplano(x,b,pesos)}
}
res<-list(pesos,b,errors)
# muestra pesos
return(res)
}
pdf("HiperplanoPerceptronIt1.pdf")
iter<-1
res <- perceptron(x, y, 1, iter)
dev.off()
setwd("~/R/posgrado/clase-3")
pdf("HiperplanoPerceptronIt1.pdf")
iter<-1
res <- perceptron(x, y, 1, iter)
dev.off()
setwd("~/R/posgrado/clase-3")
pdf("HiperplanoPerceptronIt1ap2.pdf")
iter<-1
res <- perceptron(x, y, 2, iter)
dev.off()
pdf("HiperplanoPerceptronIt1ap2.pdf")
iter<-1
res1 <- perceptron(x, y, 2, iter)
dev.off()
pdf("HiperplanoPerceptronIt1ap0-5.pdf")
iter<-1
res05 <- perceptron(x, y, 0.5, iter)
dev.off()
iter<-5
res5 <- perceptron(x, y, 1, iter)
plot(1:iter, res[[3]], type="l", lwd=2, col="red", xlab="epoch #", ylab="errors",
main="Errores vs iteracion (5)")
iter<-5
res5 <- perceptron(x, y, 1, iter)
plot(1:iter, res5[[3]], type="l", lwd=2, col="red", xlab="epoch #", ylab="errors",
main="Errores vs iteracion (5)")
perceptron <- function(x, y, eta, niter) {
# inicializacion vector de pesos
pesos <- rep(0, ncol(x))
b<-0
errors <- rep(0, niter)
# Bucle iteraciones
for (jj in 1:niter) {
# Bucle sobre el conjunto de entrenameinto
for (ii in 1:length(y)) {
# Prediccion de clase utilizando funcion salto
z <- sum(pesos* as.numeric(x[ii, ])) + b
if(z < 0) {
ypred <- -1
} else {
ypred <- 1
}
# Modificacion de pesos
delta.pesos <- eta * (y[ii] - ypred) * as.numeric(x[ii, ])
pesos <- pesos + delta.pesos
delta.b<- eta * (y[ii] - ypred)
b <- b + delta.b
if (niter==1) {dibuja.hiperplano(x,b,pesos,x[ii,])}
# Actualiza numero de errores
if ((y[ii] - ypred) != 0.0) {
errors[jj] <- errors[jj] + 1
}
}
if (niter>1) {dibuja.hiperplano(x,b,pesos)}
}
res<-list(pesos=pesos,b=b,errors=errors)
# muestra pesos
return(res)
}
iter<-5
res5 <- perceptron(x, y, 1, iter)
res5
plot(1:iter, res5[[3]], type="l", lwd=2, col="red", xlab="epoch #", ylab="errors",
main="Errores vs iteracion (5)")
plot(1:iter, res5$errors, type="l", lwd=2, col="red", xlab="epoch #", ylab="errors",
main="Errores vs iteracion (5)")
iter<-10
res10 <- perceptron(x, y, 1, iter)
plot(1:iter, res10$errors, type="l", lwd=2, col="red", xlab="epoch #", ylab="errors",
main="Errores vs iteracion (10) ")
library(caret)
library(mlbench)
library(NeuralNetTools)
data(Vehicle)
head(Vehicle)
levels(Vehicle$Class)
dim(Vehicle)
names(Vehicle)
ejTrain<-sample(1:nrow(Vehicle), 0.8*nrow(Vehicle),replace=FALSE)
training <- Vehicle[ejTrain,]
testing  <- Vehicle[-ejTrain,]
ctrl <- trainControl(
method = "cv",
number = 10
)
set.seed(1)
mlp1 <- caret:::train(Class ~., # llama asi porque puede suceder que tenga dos paquetes cargados con el mismo termino, al ponerle los puntitos lo que hago es especificar a que paquete me estoy refiriendo
data = training,
method = "mlp",
trControl = ctrl,
tuneGrid = data.frame(size=0)
)
mlp1 <- caret:::train(Class ~., # llama asi porque puede suceder que tenga dos paquetes cargados con el mismo termino, al ponerle los puntitos lo que hago es especificar a que paquete me estoy refiriendo
data = training,
method = "mlp",
trControl = ctrl,
tuneGrid = data.frame(size=0)
)
head(mlp1)
mlp1
mlp1$results
set.seed(1)
mlp2 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=0)
)
mlp2$results
set.seed(1)
mlp2 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=0)
)
mlp2$results
summary(mlp2)
ggplot() + geom_line(aes(x=1:length(mlp2$finalModel$IterativeFitError),
y=mlp2$finalModel$IterativeFitError)) +
xlab("Iteraciones con 2 neuronas oculta. 1 capa") + ylab("Error")
mlp2$finalModel
mlp2$finalModel$initFunc
mlp2$finalModel$initFuncParams
mlp2$finalModel$IterativeFitError
length(mlp2$finalModel$IterativeFitError)
set.seed(1)
mlp3 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
summaryFunction=multiClassSummary,
tuneGrid = data.frame(size=10) #se consideran 10 neuronas
)
mlp3$results
ggplot() + geom_line(aes(x=1:length(mlp3$finalModel$IterativeFitError),
y=mlp3$finalModel$IterativeFitError)) +
xlab("Iteraciones con 10 neuronas en 1 capa") + ylab("Error")
summary(mlp3)
mlp4 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=10)
)
mlp4$results
set.seed(1)
mlp4 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
#preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=10)
)
mlp4$results
set.seed(1)
mlp4 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=10)
)
mlp4$results
set.seed(1)
mlp5 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=25)
)
mlp5$results
mlp3$results
summary(mlp5)
ggplot() + geom_line(aes(x=1:length(mlp5$finalModel$IterativeFitError),
y=mlp5$finalModel$IterativeFitError)) +
xlab("Iteraciones con 25 neuronas en 1 capa") + ylab("Error")
set.seed(1)
mlp6 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneLength=5
)
mlp6$results
set.seed(1)
mlp7 <- caret:::train(
Class ~.,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=seq(25,35,5)) #genera una secuencia entre 25 y 35 de 5 en 5
)
mlp7$results
set.seed(1)
mlp8 <- caret:::train(
Class ~.,
data = training,
method = "mlpML", #mayor "anchura", permite añadir capas ocultas
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = expand.grid(layer1=16,layer2=13,layer3=0) #aca le paso cuantas neuronas quiero por cada capa (capa1, 2 y 3)
)
mlp8$results
summary(mlp8)
set.seed(1)
mlp9 <- caret:::train(
Class ~ .,
data = training,
method = "mlpML",
trControl = ctrl,
preProcess=c("center","scale"),
tuneGrid = expand.grid(layer1=seq(11,15,2),layer2=seq(9,11,2),layer3=seq(3,5,2)) #aca especificamos intervalos por capas que van de 2 en 2
)
mlp9$results
ggplot() + geom_line(aes(x=1:length(mlp9$finalModel$IterativeFitError),
y=mlp9$finalModel$IterativeFitError)) +
xlab("Iteraciones con 3 capas ocultas y similar nÃºmero de pesos") + ylab("Error")
mlp9$results
resultados<-rbind(mlp2$results[,c(2,3)], mlp3$results[,c(2,3)],mlp5$results[,c(2,3)],mlp7$results[3,c(2,3)],
c(mlp8$results$Accuracy,mlp8$results$Kappa),
c(mlp9$results$Accuracy[12],mlp9$results$Kappa[12]))
resultados
set.seed(1)
mlpit1<- caret:::train(
Class ~ .,
data = training,
method = "mlp",
trControl = ctrl,
preProcess=c("center","scale"),
tuneGrid = data.frame(size=25),
maxit = 1000
)
mlpit1$results
set.seed(1)
mlpit2 <- caret:::train(
Class ~ .,
data = training,
method = "mlpML",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = expand.grid(layer1=16,layer2=13,layer3=0),
maxit = 1500
)
mlpit2$results
set.seed(1)
mlpit3 <- caret:::train(
Class ~ .,
data = training,
method = "mlpML",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = expand.grid(layer1=14,layer2=10,layer3=5),
maxit = 2000
)
resultadosit<-rbind(mlpit1$results[,c(2,3)], mlpit2$results[,c(4,5)],mlpit3$results[,c(4,5)])
ggplot() + geom_line(aes(x=1:length(mlpit1$finalModel$IterativeFitError),
y=mlpit1$finalModel$IterativeFitError)) +
xlab("1000 Iteraciones") + ylab("Error")
ggplot() + geom_line(aes(x=1:length(mlpit2$finalModel$IterativeFitError),
y=mlpit2$finalModel$IterativeFitError)) +
xlab("1500 Iteraciones") + ylab("Error")
ggplot() + geom_line(aes(x=1:length(mlpit3$finalModel$IterativeFitError),
y=mlpit3$finalModel$IterativeFitError)) +
xlab("2000 Iteraciones") + ylab("Error")
# Vamos a ver ahora como de buenos son estos modelos con datos nuevos.
cmmlp3<-caret:::confusionMatrix(predict(mlp3,testing),testing$Class)
cmmlp5<-caret:::confusionMatrix(predict(mlp5,testing),testing$Class)
cmmlp8<-caret:::confusionMatrix(predict(mlp8,testing),testing$Class)
cmmlp9<-caret:::confusionMatrix(predict(mlp9,testing),testing$Class)
cmmlpit1<-caret:::confusionMatrix(predict(mlpit1,testing),testing$Class)
cmmlpit2<-caret:::confusionMatrix(predict(mlpit2,testing),testing$Class)
cmmlpit3<-caret:::confusionMatrix(predict(mlpit3,testing),testing$Class)
Evaluacion<-function(x)
{
return (apply(x,2,mean))
}
indices<-c(5,6,7,11)
perf<-rbind(Evaluacion(cmmlp3$byClass[,indices]),Evaluacion(cmmlp5$byClass[,indices]),
Evaluacion(cmmlp8$byClass[,indices]),Evaluacion(cmmlp9$byClass[,indices]),
Evaluacion(cmmlpit1$byClass[,indices]),Evaluacion(cmmlpit2$byClass[,indices]),
Evaluacion(cmmlpit3$byClass[,indices]))
rownames(perf)<-c("1capa-10neuronas","1capa-25neuronas","2capas","3capas",
"1capa-25neuronas-it","2capas-it","3capas-it")
cmmlp3
cmmlp3$byClass
cmmlp3$byClass[,indices]
perf
predict(mlp3, testing[1,])
dim(testing)
predict(mlp3, testing[1,-19])
library(NeuralNetTools)
training <- Vehicle[ejTrain,c(1:8,19)]
set.seed(1)
mlpp <- caret:::train(
Class ~ .,
data = training,
method = "mlp",
preProcess=c("center","scale"),
trControl = ctrl,
tuneGrid = data.frame(size=3)
)
plotnet(mlpp$finalModel, x_names=names(training)[1:ncol(training)-1],y_names=levels(training$Class))
par(mfrow=c(2,2))
olden(mlpp$finalModel, out_var='Output_bus')
olden(mlpp$finalModel, out_var='Output_opel')
olden(mlpp$finalModel, out_var='Output_saab')
olden(mlpp$finalModel, out_var='Output_van')
